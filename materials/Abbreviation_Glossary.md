# ðŸ“˜ CUDA Kernel Abbreviation Glossary

A comprehensive breakdown of commonly used abbreviations and terms used throughout high-performance WMMA-based CUDA GEMM kernels. This glossary is structured by **functionality and usage context**, inspired by NVIDIA-style repo documentation.

> âœ¨ *We will use this as a quick reference while reading kernels, debugging, or maintaining naming consistency across our HPC CUDA projects.*

---

## ðŸ§  Memory Types & Addressing

| Abbreviation                     | Description                                                |
| -------------------------------- | ---------------------------------------------------------- |
| `shmem`                          | ðŸ’£ Shared memory workspace                                 |
| `shmem_stride_bytes`             | ðŸ§® Stride in shared memory in bytes                        |
| `gmem`                           | ðŸ”µ Global memory                                           |
| `cvta_to_shared_u32`             | ðŸ”€ Convert virtual address to 32-bit shared memory address |
| `A_block_smem`, `B_block_smem`   | ðŸ§± Block-level tiles of A/B in shared memory               |
| `A_block_gmem`, `B_block_gmem`   | ðŸ“€ Block-level tiles of A/B in global memory               |
| `C_block_gmem`, `D_block_gmem`   | ðŸ“€ Global memory tiles for output C and D                  |
| `C_warp_gmem`, `D_warp_gmem`     | ðŸŒ€ Warp-level output tiles in global memory                |
| `src`, `dst`                     | ðŸ”€ Source and Destination pointers                         |
| `src_stride`, `dst_stride_bytes` | ðŸ”½ Strides in source or destination memory                 |
| `thread_offset_bytes`            | ðŸ”‚ Per-thread byte offset in memory                        |

---

## ðŸ§® Compute: MMA & Matrix Ops

| Abbreviation               | Description                                         |
| -------------------------- | --------------------------------------------------- |
| `mma`                      | âš™ï¸ Matrix Multiply-Accumulate                       |
| `mma.sync.aligned.*`       | ðŸ” PTX instruction for FP16 MMA                     |
| `ldmatrix.sync.aligned.*`  | ðŸ“… Warp-wide load from shared memory                |
| `stmatrix.*`               | ðŸ“¤ Warp-wide store to global memory                 |
| `ldmatrix_a`, `ldmatrix_b` | ðŸ§© Specialized shared memory loaders for A/B        |
| `acc_register`             | ðŸ§² Accumulator register array (C/D partial results) |
| `A_register`, `B_register` | ðŸ“Œ Per-warp A/B tiles in registers                  |
| `C_register`               | ðŸ“‚ C matrix read from global memory                 |
| `C_mma_tile`, `D_mma_tile` | ðŸ“Œ Individual MMA tile pointers in C/D matrices     |

---

## ðŸ§± Tiling Dimensions

| Abbreviation                                                           | Description                                   |
| ---------------------------------------------------------------------- | --------------------------------------------- |
| `BM_dim`, `BN_dim`, `BK_dim`                                           | ðŸ§± Block-level tiling dimensions (BlockM/N/K) |
| `WM_dim`, `WN_dim`, `WK_dim`                                           | ðŸŽ¯ Warp-level tiling dimensions (WarpM/N/K)   |
| `MMA_M_dim`, `MMA_N_dim`, `MMA_K_dim`                                  | ðŸ’ª MMA intrinsic tile sizes                   |
| `mma_tiles_per_warp_m`, `mma_tiles_per_warp_n`, `mma_tiles_per_warp_k` | ðŸ“Š MMA tiles per warp along M/N/K             |

---

## ðŸ§µ Thread & Warp Layout

| Abbreviation                                                  | Description                              |
| ------------------------------------------------------------- | ---------------------------------------- |
| `warp_m`, `warp_n`                                            | ðŸ§¶ Warp indices within a block           |
| `block_m`, `block_n`                                          | ðŸ“¦ Block indices in grid                 |
| `threadIdx.x`, `threadIdx.y`                                  | ðŸ§µ Thread index within warp/block        |
| `WARP_SIZE`                                                   | âš™ï¸ Fixed as 32 threads                   |
| `WARPS_PER_BLOCK_M`, `WARPS_PER_BLOCK_N`, `WARPS_PER_BLOCK_K` | ðŸ“‰ Number of warps per block along M/N/K |
| `ThreadsM`, `ThreadsN`, `NumThreads`                          | ðŸ”¦ Block thread configuration            |
| `BlocksM`, `BlocksN`                                          | ðŸ§± Grid size in M/N dimensions           |

---

## ðŸš€ Kernel Execution Parameters

| Abbreviation                                   | Description                                      |
| ---------------------------------------------- | ------------------------------------------------ |
| `alpha`, `beta`                                | âœ´ï¸ Scaling factors in GEMM epilogue              |
| `alpha_`, `beta_`                              | ðŸ”€ Casted half-precision versions                |
| `tileMemcpy*`                                  | ðŸš› Tile memory copy utilities                    |
| `tileMemcpySwizzle*`                           | ðŸ”„ Memory swizzling copy functions               |
| `int_log2`, `SWIZZLE_BITS_*`, `SWIZZLE_MASK_*` | ðŸ§  Bitwise swizzling utilities                   |
| `offset_direction`                             | â†”ï¸ Used for ping-pong double buffering           |
| `BUFFER_SIZE`                                  | ðŸ“¦ Shared memory buffer size per tile            |
| `shmem_bytes`                                  | ðŸ“¦ Total shared memory size allocated per kernel |

---

## ðŸ§ª Verification, Logging & Utility

| Abbreviation          | Description                                  |
| --------------------- | -------------------------------------------- |
| `sgemm_params`        | âš™ï¸ Struct holding all GEMM launch parameters |
| `KernelLogger`        | ðŸ“Š Measures and logs kernel GFLOPS           |
| `sgemm_verify`        | ðŸ§ª Verifies correctness of results           |
| `elementwise_isclose` | ðŸ§® Compares float values element-wise        |
| `CUDA_CHECK()`        | ðŸ›‘ Error checking macro                      |

---

## ðŸ”¬ Advanced Register Swizzling

| Abbreviation                           | Description                                            |
| -------------------------------------- | ------------------------------------------------------ |
| `A_gmem_cache_reg`, `B_gmem_cache_reg` | ðŸ“€ float4-based prefetch registers                     |
| `src_reg`, `dst_reg`                   | ðŸ”€ Used in looped copy operations                      |
| `swizzled_offset`, `logical_offset`    | ðŸŒ€ Bit-manipulated offsets for avoiding bank conflicts |

---

## ðŸ› ï¸ Code Utility Macros & Constants

| Abbreviation                | Description                        |
| --------------------------- | ---------------------------------- |
| `RAND_HALF`                 | ðŸŽ² Random value in half precision  |
| `cvta_to_shared_u32()`      | ðŸ”€ Cast to 32-bit shared pointer   |
| `cudaFuncSetAttribute(...)` | ðŸ§° Set dynamic shared memory limit |

---

## ðŸ“† Launch Config & Epilogue Details

| Abbreviation                 | Description                         |
| ---------------------------- | ----------------------------------- |
| `gridDim`, `blockDim`        | ðŸš€ CUDA kernel launch configuration |
| `num_block_tiles_k`          | ðŸ”¢ Number of k-tiles per GEMM block |
| `C_warp_tile`, `D_warp_tile` | ðŸ§± Warp tile pointer in C and D     |
| `kernel_6_launch(...)`       | ðŸ’¥ Entry point to launch `kernel_6` |
| `num_runs`                   | ðŸ” Iterations for benchmarking      |

---

## ðŸ“¦ Epilogue Fusion

| Abbreviation               | Description                             |
| -------------------------- | --------------------------------------- |
| `ldmatrix_m16n8_gmem`      | ðŸ“… Load C tiles for beta scaling        |
| `stmatrix_m16n8`           | ðŸ“¤ Store final scaled output to D       |
| `acc_register_`            | ðŸ”€ Half-view of accumulator registers   |
| `C_register`, `C_mma_tile` | ðŸ“Œ Intermediate C tile used in epilogue |
| `D_mma_tile`               | ðŸ“Œ Final output tile in D               |

---

## ðŸŒŸ Final Words

> This glossary grows with our kernel. We'll update as we introduce new optimizations (e.g., FP8, TMA, async pipelines). ðŸš€
